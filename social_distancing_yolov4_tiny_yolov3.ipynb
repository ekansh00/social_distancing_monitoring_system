{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "combined_model_for detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "10H7WTogdc77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image, ImageDraw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26E3vZo6XnsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da_LKa8xXpvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0JxPZq0a6xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the video from drive and dividing it into frames with numbering as frame0,frame1,frame2....\n",
        " \n",
        "# Read the video from specified path \n",
        "cam = cv2.VideoCapture(\"/content/gdrive/My Drive/tiny_yolov3/test_videos/new.mp4\") \n",
        "\n",
        "currentframe = 0\n",
        "  \n",
        "while(True): \n",
        "      \n",
        "    # reading from frame \n",
        "    ret,frame = cam.read() \n",
        "  \n",
        "    if ret: \n",
        "        # if video is still left continue creating images \n",
        "        name = '/content/gdrive/My Drive/tiny_yolov3/test_videos/frames/frame' + str(currentframe) + '.jpg'\n",
        "        print ('Creating...' + name) \n",
        "         # writing the extracted images \n",
        "        cv2.imwrite(name, frame) \n",
        "  \n",
        "        # increasing counter so that it will \n",
        "        # show how many frames are created \n",
        "        currentframe += 1\n",
        "    else: \n",
        "        break\n",
        "  \n",
        "# Release all space and windows once done \n",
        "cam.release() \n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItLBTUDba_eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code for creating text file containing paths to all the frames extracted from the video(will be used in detections)\n",
        "file1 = open(\"images.txt\",\"w\")\n",
        "for i in range (0,currentframe):\n",
        "  a=\"/mydrive/tiny_yolov3/test_videos/frames/frame\"+str(i)+\".jpg\"+\"\\n\"\n",
        "  file1.write(a)\n",
        "file1.close"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtqL9VkHbBYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code for detections with yolo on all the frames and creating json format for all the detections done frame by frame\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CEo_oYCbDfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "# (For tiny yolov3 do not do it only applicable for yolov4)\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9zvwJKAbFPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3CUuzMTbGxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di3XlRMHbJQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting weights of yolo v4(tiny yolo v3)\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgF-VZdne8pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define helper functions\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "# use this to upload files\n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload() \n",
        "  for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "      f.write(data)\n",
        "      print ('saved file', name)\n",
        "\n",
        "# use this to download a file  \n",
        "def download(path):\n",
        "  from google.colab import files\n",
        "  files.download(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6qawVd37jk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ee41164-5a0b-485e-d3d1-20a357620108"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/darknet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_kw8E60bW_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code for detections on multiple images with there paths specified in images.txt file(A json file will be created that will contain detections of each frame)\n",
        "!./darknet detector test cfg/coco.data cfg/yolov3-tiny.cfg /mydrive/tiny_yolov3/yolov3-tiny.weights /mydrive/tiny_yolov3/test_videos/frames_town_centre/frame32.jpg -ext_output\n",
        " \n",
        "# !./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights /mydrive/tiny_yolov3/test_videos/frames/frame0.jpg -ext_output\n",
        "\n",
        "# !./darknet detector test cfg/coco.data cfg/yolov3-tiny.cfg /mydrive/tiny_yolov3/yolov3-tiny.weights -ext_output -dont_show -out result.json < /mydrive/tiny_yolov3/test_videos/images_short.txt\n",
        "\n",
        "# !./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -ext_output -dont_show -out result.json < /mydrive/tiny_yolov3/test_videos/images.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4TwzZLyfcwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing made on json format and extracting the bounding box coordinates\n",
        "f=open(\"/content/darknet/result.json\")\n",
        "data=json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1mHZqUJuCrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for finding eucledian distance between all the points in a given array\n",
        "from scipy.spatial import distance\n",
        "def compute_distance(midpoints,num):\n",
        "  dist = np.zeros((num,num))\n",
        "  for i in range(num):\n",
        "    for j in range(i+1,num):\n",
        "      if i!=j:\n",
        "        dst = distance.euclidean(midpoints[i], midpoints[j])\n",
        "        dist[i][j]=dst\n",
        "  return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4ozk0TKuvPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for returning an array based on the 2d array formed from compute_distance function\n",
        "def find_closest(dist,num,thresh):\n",
        "  p1=[]\n",
        "  p2=[]\n",
        "  d=[]\n",
        "  for i in range(num):\n",
        "    for j in range(i,num):\n",
        "      if( (i!=j) & (dist[i][j]<=thresh)):\n",
        "        p1.append(i)\n",
        "        p2.append(j)\n",
        "        d.append(dist[i][j])\n",
        "  return p1,p2,d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAvJmIWjLiW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding the matrix for conversion into perspective coordinates(only valid for oxford town center dataset)\n",
        "src = np.float32([[1150,30], [1700,80], [1150,650], [100,475]])\n",
        "dst = np.float32([[0,0], [1050,0], [1050, 570], [0, 570]])\n",
        "matrix = cv2.getPerspectiveTransform(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPiMHaZKUETb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for transforming the midpoints into the birds eye coordinates\n",
        "def transform_pts(point,prespective_transform):\n",
        "  pts = np.float32([[point[0],point[1]]])\n",
        "  pts=np.array([pts])\n",
        "  bd_pnt = cv2.perspectiveTransform(pts, prespective_transform)[0][0]\n",
        "  return ((int(bd_pnt[0]),int(bd_pnt[1]))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r-UZEVYvP1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for making bounding boxes on all frames only around person class(green as well as red) \n",
        "z=len(data)\n",
        "for i in range(0,z):\n",
        "  m=data[i][\"objects\"]\n",
        "  f=[]\n",
        "\n",
        "  for j in range(0,len(m)):\n",
        "    n=m[j][\"relative_coordinates\"]\n",
        "    f.append(n)\n",
        " \n",
        "  class_iden=[]\n",
        "  for w in range(0,len(m)):\n",
        "    l=m[w][\"class_id\"]\n",
        "    class_iden.append(l)\n",
        "\n",
        "  x_center=[]\n",
        "  for k in range(0,len(data[i][\"objects\"])):\n",
        "    b=f[k][\"center_x\"]\n",
        "    x_center.append(b)\n",
        "\n",
        "  y_center=[]\n",
        "  for k in range(0,len(data[i][\"objects\"])):\n",
        "    b=f[k][\"center_y\"]\n",
        "    y_center.append(b)\n",
        "\n",
        "  height=[]\n",
        "  for k in range(0,len(data[i][\"objects\"])):\n",
        "    b=f[k][\"height\"]\n",
        "    height.append(b)\n",
        "\n",
        "  width=[]\n",
        "  for k in range(0,len(data[i][\"objects\"])):\n",
        "    b=f[k][\"width\"]\n",
        "    width.append(b)\n",
        "\n",
        "  dict = {'x_center': x_center, 'y_center': y_center, 'height': height, 'width': width, 'class_id': class_iden}  \n",
        "  df = pd.DataFrame(dict)\n",
        "  # Multiplication with height and width of image(normalisation)\n",
        "  df[\"x_top\"]=(df[\"x_center\"]-(df[\"width\"]/2))*(1280)\n",
        "  df[\"y_top\"]=(df[\"y_center\"]-(df[\"height\"]/2))*(720)\n",
        "  df[\"x_bottom\"]=(df[\"x_center\"]+(df[\"width\"]/2))*(1280)\n",
        "  df[\"y_bottom\"]=(df[\"y_center\"]+(df[\"height\"]/2))*(720)\n",
        "\n",
        "  df[\"x_bottom_mid\"]=(df[\"x_top\"]+df[\"x_bottom\"])/2\n",
        "  df[\"y_bottom_mid\"]=df[\"y_bottom\"]\n",
        "\n",
        "  df=df[df[\"class_id\"]==0]\n",
        "  df=df.reset_index()\n",
        "  df=df.drop([\"x_center\",\"y_center\",\"height\",\"width\",\"class_id\",\"index\"],axis=1)\n",
        "  \n",
        "  num=len(df)\n",
        "\n",
        "  # Computing midpoints of all the detection boxes\n",
        "  midpoints=[]\n",
        "  for k in range (0,num):\n",
        "    mid_point=(int(df.loc[k][\"x_bottom_mid\"]),int(df.loc[k][\"y_bottom_mid\"]))\n",
        "    midpoints.append(mid_point)\n",
        "\n",
        "  # # converting the midpoints array into perspective coordinates\n",
        "  # for i in range(0,num):\n",
        "  #   midpoints[i]=transform_pts(midpoints[i],matrix)\n",
        "\n",
        "  # computing the 2d \n",
        "  dist= compute_distance(midpoints,num)\n",
        "\n",
        "\n",
        "  thresh=100\n",
        "  p1,p2,d=find_closest(dist,num,thresh)\n",
        "  w = pd.DataFrame({\"p1\":p1,\"p2\":p2,\"dist\":d})\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  image=cv2.imread(\"/mydrive/tiny_yolov3/test_videos/frames/frame\"+str(i)+\".jpg\")\n",
        "  color=(0, 255, 0) \n",
        "  thickness=2\n",
        "  for k in range(0,num):\n",
        "    start_point=(int(df.loc[k][\"x_top\"]),int(df.loc[k][\"y_top\"]))\n",
        "    end_point=(int(df.loc[k][\"x_bottom\"]),int(df.loc[k][\"y_bottom\"]))\n",
        "    image=cv2.rectangle(image,start_point,end_point,color,thickness)\n",
        "\n",
        "  risky = np.unique(p1+p2)\n",
        "  for k in risky:\n",
        "    x1,y1,x2,y2,z1,z2 = df.loc[k]\n",
        "    image= cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (255,0,0), 2)\n",
        "  \n",
        "  u=\"/mydrive/tiny_yolov3/images_with_detection_boxes_new/frame\"+str(i)+\".jpg\"\n",
        "  cv2.imwrite(u,image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UjDlp7Yv1Sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for combining all the frames with bounding boxes in a single video\n",
        "import os \n",
        "import re\n",
        "frames = os.listdir('/mydrive/tiny_yolov3/images_with_detection_boxes_new')\n",
        "frames.sort(key=lambda f: int(re.sub('\\D', '', f)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5fSxPPrwHCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "frame_array=[]\n",
        "\n",
        "\n",
        "for i in range(len(frames)):\n",
        "    \n",
        "    #reading each files\n",
        "    img = cv2.imread('/content/gdrive/My Drive/tiny_yolov3/images_with_detection_boxes_new/'+frames[i])\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    height, width, layers = img.shape\n",
        "    size = (width,height)\n",
        "    \n",
        "    #inserting the frames into an image array\n",
        "    frame_array.append(img)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3OVxgttwLLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = cv2.VideoWriter('sample_output_new.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44cU2JxHwOFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(frame_array)):\n",
        "    # writing to a image array\n",
        "    out.write(frame_array[i])\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}