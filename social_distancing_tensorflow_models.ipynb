{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of find_dist_birdeye.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtHgQHddDJe8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "175fc899-c8a9-47f3-9d5f-eba458c515ab"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaK56ctLXQYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-object-detection-api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOIr5wu4DY2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import math\n",
        "import cv2\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import itertools\n",
        "from itertools import compress\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "### Model preparation variable\n",
        "PATH_TO_FROZEN_GRAPH ='/content/drive/My Drive/evaluation/pretrainedmodel/ssd_mobilenet_v1_0.75_depth/frozen_inference_graph.pb'\n",
        "PATH_TO_LABELS ='/content/drive/My Drive/model2/data/labelmap.pbtxt'\n",
        "NUM_CLASSES =1 #remember number of objects you are training? cool.\n",
        "\n",
        "\n",
        "### Load a (frozen) Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "###Loading label map\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Load image into numpy function\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###STATING THE PATH TO IMAGES TO BE TESTED\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}.jpg'.format(i)) for i in ['tt'] ]\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "\n",
        "### Function to run inference on a single image which will later be used in an iteration\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      start=time.time()\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: image})\n",
        "      \n",
        "      end=time.time()\n",
        "      print(end-start)\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.int64)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d65Ov_0mQIjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_dis(p1, p2, distance_w, distance_h):   \n",
        "    h = abs(p2[1]-p1[1])\n",
        "    w = abs(p2[0]-p1[0]) \n",
        "    dis_w = float((w/distance_w)*490)\n",
        "    dis_h = float((h/distance_h)*330)\n",
        "    return int(np.sqrt(((dis_h)**2) + ((dis_w)**2)))\n",
        "\n",
        "def calculate_points(bounding_box,w,h):\n",
        "  x=int(((bounding_box[3]-bounding_box[1])/2+bounding_box[1])*w)\n",
        "  y=int(bounding_box[2]*h)\n",
        "  return (x,y)\n",
        "\n",
        "def transform_pts(point,prespective_transform):\n",
        "  pts = np.float32([[point[0],point[1]]])\n",
        "  pts=np.array([pts])\n",
        "  bd_pnt = cv2.perspectiveTransform(pts, prespective_transform)[0][0]\n",
        "  return (int(bd_pnt[0]),int(bd_pnt[1]))\n",
        "\n",
        "def get_distances(detection_boxes,detection_points,detection_transformed_pts,distance_w, distance_h):\n",
        "\n",
        "    pnts = []\n",
        "    box=[]  \n",
        "\n",
        "    for i in range(len(detection_transformed_pts)):\n",
        "        for j in range(len(detection_transformed_pts)):\n",
        "            if i != j:\n",
        "                dist = cal_dis(detection_transformed_pts[i], detection_transformed_pts[j], distance_w, distance_h)\n",
        "                if dist <=200:\n",
        "                    pnts.append((detection_points[i], detection_points[j]))\n",
        "                    box.append(detection_boxes[i])\n",
        "                    box.append(detection_boxes[j])          \n",
        "    return pnts,box\n",
        "\n",
        "\n",
        "def get_normalized_boxes(bounding_box,w,h):\n",
        "    ymin=int(bounding_box[0]*h)\n",
        "    xmin=int(bounding_box[1]*w)\n",
        "    ymax=int(bounding_box[2]*h)\n",
        "    xmax=int(bounding_box[3]*w)\n",
        "    return((xmin,xmax,ymin,ymax))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXSKWkLbVHEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def show_inference(image_path):\n",
        "  \n",
        "  person_class = 1\n",
        "  score_treshold = 0.5\n",
        "  image = Image.open(image_path)\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
        "\n",
        "  '''\n",
        "  #4 points selection and conversion\n",
        "  src = np.float32([[185, 667], [1621,904], [2374,141], [1565, 46]])\n",
        "  dst = np.float32([[0,2684], [1510,2684], [1510, 0], [0, 0]])\n",
        "  prespective_transform = cv2.getPerspectiveTransform(src, dst)\n",
        "\n",
        "  #89pixel = 490 cms 1 cm= 89/490\n",
        "  #real world distance conversion\n",
        "  pts = np.float32([[1261,495], [1922,597], [889,600], [1175,431]])\n",
        "  pts=np.array([pts])\n",
        "  warped_pt = cv2.perspectiveTransform(pts, prespective_transform)[0] \n",
        "  distance_w = np.sqrt((warped_pt[0][0] - warped_pt[1][0]) ** 2 + (warped_pt[0][1] - warped_pt[1][1]) ** 2)\n",
        "  distance_h = np.sqrt((warped_pt[2][0] - warped_pt[3][0]) ** 2 + (warped_pt[2][1] - warped_pt[3][1]) ** 2)\n",
        "  '''\n",
        "  #Filter persons and boxes with a score higher than 50% and drawing all boxes\n",
        "  boolPersons = output_dict['detection_classes'] == person_class\n",
        "  boolScores = output_dict['detection_scores'] > score_treshold\n",
        "  boolCombined = np.logical_and(boolPersons,boolScores)\n",
        "\n",
        "  output_dict['detection_scores'] = output_dict['detection_scores'][boolCombined]\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'][boolCombined]\n",
        "  output_dict['detection_boxes'] = output_dict['detection_boxes'][boolCombined]\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=2,\n",
        "      min_score_thresh=score_treshold)\n",
        "  \n",
        "  #image width and size for normalization \n",
        "  im = Image.fromarray(image_np)\n",
        "  '''\n",
        "  w,h= im.size\n",
        "  #get the bottom centre point of each box and then transform it\n",
        "  output_dict['detection_points'] = [calculate_points(x,w,h) for x in output_dict['detection_boxes']]\n",
        "  output_dict['detection_transformed_pts']=[transform_pts(x,prespective_transform) for x in output_dict['detection_points']]\n",
        "\n",
        "  #calculting distance and then saving the box and points for people who broke social distancing\n",
        "  output_dict['detection_permutations'],output_dict['detection_boxes'] =get_distances(output_dict['detection_boxes'],output_dict['detection_points'],output_dict['detection_transformed_pts'],distance_w, distance_h)\n",
        "  output_dict['detection_boxes']=[get_normalized_boxes(x,w,h) for x in output_dict['detection_boxes']]\n",
        "  #draw red boxes and crop images\n",
        "  draw2 = ImageDraw.Draw(im)\n",
        "  for box in output_dict['detection_boxes']: \n",
        "    xmin=box[0]\n",
        "    xmax=box[1]\n",
        "    ymin=box[2]\n",
        "    ymax=box[3]\n",
        "    #im1 = im.crop((xmin, ymin, xmax, ymax))\n",
        "    #im1=im1.save('frame_'+str(xmin)+'.jpg')\n",
        "    draw2.line([(xmin,ymin), (xmin, ymax), (xmax, ymax), (xmax,ymin),(xmin,ymin)],\n",
        "              width=4,\n",
        "              fill=255)\n",
        "\n",
        "\n",
        "  #draw lines\n",
        "  draw = ImageDraw.Draw(im)\n",
        "  for point in output_dict['detection_permutations']: \n",
        "     draw.line((point[0],point[1]), fill=255, width=2)\n",
        "  \n",
        "  \n",
        "   #uncomment the below lines for video and comment the display line \n",
        "  #im_np = load_image_into_numpy_array(im)\n",
        "  #return(im_np)\n",
        "  '''\n",
        "  display(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1vVCJQKXWZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "\n",
        "start=time.time()\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  show_inference(image_path)\n",
        "\n",
        "end=time.time()\n",
        "print(end-start)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "#code for making a video\n",
        "\n",
        "%cd '/content/drive/My Drive'\n",
        "from moviepy.editor import VideoFileClip\n",
        "write_output = 'output_video_another.mp4'\n",
        "clip1 = VideoFileClip(\"video_1.mp4\")\n",
        "white_clip = clip1.fl_image(show_inference)\n",
        "%time white_clip.write_videofile(write_output, audio=False)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l36dtvX22Guk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}